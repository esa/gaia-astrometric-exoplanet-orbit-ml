#   Copyright (c) European Space Agency, 2025.
#
#   This file is subject to the terms and conditions defined in file 'LICENCE.txt', which
#   is part of this source code package. No part of the package, including
#   this file, may be copied, modified, propagated, or distributed except according to
#   the terms contained in the file ‘LICENCE.txt’.

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and Imports\n",
    "This cell initializes the notebook by loading necessary extensions and importing required libraries and modules. It also sets up the environment by creating a directory for storing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import pickle as pk\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gaia_ad\n",
    "from load_data import load_data\n",
    "from compute_shap import compute_shap\n",
    "from create_occurence_df import create_occurence_df\n",
    "from plots import plot_combined_individual_feature_importance\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.makedirs(\"paper/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Sort Methods\n",
    "This cell loads the top candidates for each method from the results directory, sorts them, and creates a DataFrame with the occurrence of each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_compare = 50  # Top how many to compare\n",
    "methods = glob(\"results/top*\")\n",
    "methods.sort()\n",
    "candidates, top, method_names = create_occurence_df(methods, N_compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Scores and Calculate Statistics\n",
    "This cell loads score files, calculates mean and standard deviation for each method, and stores them in DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also create a pd with the scores for each method\n",
    "results = glob(\"results/scores*\")\n",
    "results.sort()\n",
    "example_score = np.load(results[0], allow_pickle=True).item()\n",
    "scores = pd.DataFrame(index=example_score.keys())\n",
    "stds = pd.DataFrame(index=example_score.keys())\n",
    "# print(\"Found results:\", results)\n",
    "for result, name in zip(results, method_names):\n",
    "    # # Doublecheck method name\n",
    "    # print(\n",
    "    #     name, \" - vs. - \", result.split(\"_\")[1] + \"_\" + result.split(\"_\")[2] + \"_\" + result.split(\"for_\")[1][:12]\n",
    "    # )\n",
    "    assert (\n",
    "        name\n",
    "        == result.split(\"_\")[1] + \"_\" + result.split(\"_\")[2] + \"_\" + result.split(\"for_\")[1][:12]\n",
    "    )\n",
    "    score = np.load(result, allow_pickle=True).item()\n",
    "    scores[name] = [np.mean(score[key]) for key in score.keys()]\n",
    "    stds[name] = [np.std(score[key]) for key in score.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets for Anomaly Detection\n",
    "This cell loads datasets for each method, preparing them for anomaly detection analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the top N candidates, we look at all models that classified it as an anomaly\n",
    "# We need to get the datasets again for this\n",
    "datasets = {}\n",
    "gaia_ad.set_log_level(\"WARNING\")  # Avoid spam from load_data\n",
    "for method in methods:\n",
    "    X, y, y_original, df, non_candidates, label_mapping, _ = load_data(\n",
    "        dataset_version=\"0.0.6\",\n",
    "        drop_NSS=method.split(\"_\")[2] == \"ssc\",\n",
    "        make_binary=True,\n",
    "        clean=True,\n",
    "        drop_nan_columns=False,\n",
    "        drop_nan_rows=False,\n",
    "        label_for_high_confidence_substellar=method.split(\".csv\")[0][-1],\n",
    "        path=\"data/0.0.6/\",\n",
    "    )\n",
    "    datasets[method] = (X, y, y_original, df, non_candidates, label_mapping)\n",
    "\n",
    "features = datasets[methods[0]][0].columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute SHAP Values\n",
    "This cell computes SHAP values for the candidates using the loaded datasets and methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_shap_values = compute_shap(\n",
    "    methods,\n",
    "    datasets,\n",
    "    candidates,\n",
    "    features,\n",
    "    plot=False,\n",
    "    path=\"results/shap_candidates/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper Function\n",
    "This cell defines a helper function to generate a descriptive name for each run based on the file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_name(path):\n",
    "    name = \"\"\n",
    "    if \"rf\" in path:\n",
    "        name += \"RandomForest - Dataset \"\n",
    "    elif \"xgb\" in path:\n",
    "        name += \"XGBoost - Dataset \"\n",
    "\n",
    "    if \"nss\" in path and \"better_ssc=1\" in path:\n",
    "        name += \" D2\"\n",
    "    elif \"nss\" in path and \"better_ssc=0\" in path:\n",
    "        name += \" D1\"\n",
    "    elif \"ssc\" in path and \"better_ssc=1\" in path:\n",
    "        name += \" D4\"\n",
    "    elif \"ssc\" in path and \"better_ssc=0\" in path:\n",
    "        name += \" D3\"\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Feature Importance for Selected Candidates\n",
    "This cell plots the feature importance for a list of selected candidates using SHAP values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots import plot_individual_feature_importance\n",
    "from compute_shap import xgb_shap_transform_scale\n",
    "\n",
    "source_ids_to_plot = [\n",
    "    43574131143039104,\n",
    "    3751763647996317056,\n",
    "    2884087104955208064,\n",
    "    557717892980808960,\n",
    "    246890014559489792,\n",
    "    4702845638429469056,\n",
    "]\n",
    "cand_to_plot = pd.DataFrame(columns=[\"source_id\"])\n",
    "cand_to_plot[\"source_id\"] = source_ids_to_plot\n",
    "\n",
    "path = \"paper/candidates/\"\n",
    "overall_shap_values = pd.DataFrame(columns=features)\n",
    "# We start by loading the clf that classified it as positive and the split_index\n",
    "for _, candidate in tqdm(\n",
    "    cand_to_plot.iterrows(),\n",
    "    total=len(cand_to_plot),\n",
    "    desc=\"Feature Importance per Candidate Computation\",\n",
    "):\n",
    "    # Create a folder for this candidate in results/feature_importance\n",
    "    if not os.path.exists(path + str(candidate.source_id)):\n",
    "        os.makedirs(path + str(candidate.source_id))\n",
    "\n",
    "    shaps, base, data, names = [], [], [], []\n",
    "    shaps_xgb, base_xgb, data_xgb, names_xgb = [], [], [], []\n",
    "    for idx, method in enumerate(methods):\n",
    "        # print(\"Candidate\", candidate.source_id, \"was classified as positive by method\", method)\n",
    "\n",
    "        name = \"\".join(method.partition(\"_\")[1:]).partition(\".csv\")[0]\n",
    "        split_index = pd.read_csv(\n",
    "            \"results/split_index\" + name + \".csv\", dtype={\"source_id\": np.int64}\n",
    "        )\n",
    "        # Get split_index of this candidate\n",
    "        assert candidate.source_id in split_index.source_id.values, (\n",
    "            \"Candidate source_id \"\n",
    "            + str(candidate.source_id)\n",
    "            + \" not found in split_index of method \"\n",
    "            + name\n",
    "        )\n",
    "        split_index_candidate = split_index[split_index.source_id == candidate.source_id][\n",
    "            \"split_index\"\n",
    "        ].values[0]\n",
    "        idx = split_index[split_index.source_id == candidate.source_id].index[0]\n",
    "        clf = pk.load(open(\"results/clfs\" + name + \".pk\", \"rb\"))\n",
    "        clf = clf[int(split_index_candidate)]\n",
    "        X = datasets[method][0]\n",
    "\n",
    "        # Get the shap tree explainer for this clf\n",
    "        explainer = shap.TreeExplainer(clf)\n",
    "\n",
    "        # Get the shap values for this candidate\n",
    "        # print(\"----------------------------------\")\n",
    "        # print(method)\n",
    "        # print(\"idx\", idx)\n",
    "        # print(X.shape)\n",
    "        shap_values = explainer(X.iloc[idx : idx + 1])\n",
    "\n",
    "        # Discard the 0 class component if present\n",
    "        if len(shap_values.values.shape) == 3:\n",
    "            shap_values.values = shap_values.values[:, :, 1]\n",
    "        if isinstance(shap_values.base_values[0], np.ndarray):\n",
    "            shap_values.base_values = [shap_values.base_values[0][1]]\n",
    "\n",
    "        pred = clf.predict_proba(X.iloc[idx : idx + 1])[0][1]\n",
    "        s = str(name[1:]) + \"_pred=\" + str(pred)\n",
    "        if \"xgb\" in method:\n",
    "            # shap_vals,base_val = xgb_shap_transform_scale(shap_values,pred)\n",
    "            # shap_values.values = shap_vals\n",
    "            # shap_values.base_values = [base_val]\n",
    "            shaps_xgb.append(shap_values.values)\n",
    "            base_xgb.append(shap_values.base_values)\n",
    "            data_xgb.append(shap_values.data)\n",
    "            names_xgb.append(s)\n",
    "        else:\n",
    "            shaps.append(shap_values.values)\n",
    "            base.append(shap_values.base_values)\n",
    "            data.append(shap_values.data)\n",
    "            s = str(name[1:]) + \"_pred=\" + str(pred)\n",
    "            names.append(s)\n",
    "        # print(type(clf),pred)\n",
    "\n",
    "        # Store the shap values for this candidate\n",
    "        overall_shap_values.loc[str(candidate.source_id) + \"_\" + method] = shap_values.values[0]\n",
    "        # print(overall_shap_values)\n",
    "        # plot_individual_feature_importance(shap_values, explainer, name, candidate, features, path)\n",
    "    # print(\"shaps\",shaps_xgb)\n",
    "    # print(\"base\",base_xgb)\n",
    "    # print(\"data\",data_xgb)\n",
    "    names = [get_run_name(name) for name in names]\n",
    "    names_xgb = [get_run_name(name) for name in names_xgb]\n",
    "    plot_combined_individual_feature_importance(\n",
    "        str(candidate.source_id),\n",
    "        shaps,\n",
    "        base,\n",
    "        data,\n",
    "        features,\n",
    "        names,\n",
    "        path + str(candidate.source_id) + \"_rf\",\n",
    "    )\n",
    "    plot_combined_individual_feature_importance(\n",
    "        str(candidate.source_id),\n",
    "        shaps_xgb,\n",
    "        base_xgb,\n",
    "        data_xgb,\n",
    "        features,\n",
    "        names_xgb,\n",
    "        path + str(candidate.source_id) + \"_xgb\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample SHAP Values for Random Samples\n",
    "This cell evaluates SHAP values for a random sample of data points from each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Evaluate SHAP values for N_to_sample random samples per method\n",
    "N_to_sample = 50\n",
    "random_shap_sample = pd.DataFrame(columns=features)\n",
    "associated_feature = pd.DataFrame(columns=features)\n",
    "np.random.seed(42)\n",
    "for method in tqdm(methods):\n",
    "    name = \"\".join(method.partition(\"_\")[1:]).partition(\".csv\")[0]\n",
    "    clfs = pk.load(open(\"results/clfs\" + name + \".pk\", \"rb\"))\n",
    "\n",
    "    for model_idx, clf in tqdm(enumerate(clfs)):\n",
    "        # Pick N_to_sample source ids in corresponding dataset\n",
    "        split_index = pd.read_csv(\n",
    "            \"results/split_index\" + name + \".csv\", dtype={\"source_id\": np.int64}\n",
    "        )\n",
    "        ds = split_index.source_id\n",
    "        ids = np.random.choice(ds, N_to_sample)\n",
    "        X = datasets[method][0]\n",
    "        idx = split_index.source_id[split_index.source_id.isin(ids)].index\n",
    "        X_val = X.iloc[idx]\n",
    "        explainer = shap.TreeExplainer(clf)\n",
    "        shap_values = explainer(X.iloc[idx])\n",
    "        # Discard the 0 class component if present\n",
    "        if len(shap_values.values.shape) == 3:\n",
    "            shap_values.values = shap_values.values[:, :, 1]\n",
    "        for sample_idx, sample in enumerate(shap_values.values):\n",
    "            source_id = str(ids[sample_idx])\n",
    "            random_shap_sample.loc[method + \"_\" + str(model_idx) + \"_\" + source_id] = sample\n",
    "            associated_feature.loc[method + \"_\" + str(model_idx) + \"_\" + source_id] = X.iloc[\n",
    "                idx[sample_idx]\n",
    "            ]\n",
    "print(\"Got a total of \", random_shap_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Full Dataset for Candidate Analysis\n",
    "This cell loads the full dataset to analyze the features of the candidates identified by SHAP values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_big, _, y_original_big, df_big, _, _, _ = load_data(\n",
    "    dataset_version=\"0.0.6\",\n",
    "    drop_NSS=False,\n",
    "    make_binary=True,\n",
    "    clean=True,\n",
    "    drop_nan_columns=False,\n",
    "    drop_nan_rows=False,\n",
    "    label_for_high_confidence_substellar=0,\n",
    "    path=\"data/0.0.6/\",\n",
    ")\n",
    "\n",
    "source_ids = overall_shap_values.index.str.split(\"_\").str[0].astype(np.int64)\n",
    "# print(source_ids)\n",
    "# for each source_id get the corresponding index in X\n",
    "data_idx = [df_big[df_big.source_id == source_id].index[0] for source_id in source_ids]\n",
    "# print(data_idx)\n",
    "# Get the X values for this feature allowing duplicate rows\n",
    "X_candidates = X_big.iloc[data_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot SHAP Value Distributions\n",
    "This cell creates violin plots to visualize the distribution of SHAP values of the candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=300)\n",
    "shap.plots.violin(\n",
    "    overall_shap_values.values,\n",
    "    features=X_candidates.values,\n",
    "    feature_names=list(features),\n",
    "    max_display=5,\n",
    "    plot_type=\"layered_violin\",\n",
    "    plot_size=1.0,\n",
    "    show=False,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"paper/shap_dist_candidates.pdf\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot SHAP Value Distributions for Random Samples\n",
    "This cell creates violin plots to visualize the distribution of SHAP values for random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=300)\n",
    "shap.plots.violin(\n",
    "    random_shap_sample.values,\n",
    "    features=associated_feature.values,\n",
    "    feature_names=list(features),\n",
    "    max_display=5,\n",
    "    plot_type=\"layered_violin\",\n",
    "    plot_size=1.0,\n",
    "    show=False,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"paper/shap_dist_random.pdf\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot SHAP Values vs. Feature Distribution\n",
    "This cell plots the scatter of SHAP values against the histogram of the feature distribution for a specific feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature = \"radial_velocity_error\"\n",
    "feature = \"mass_function_msun\"\n",
    "# For each feature plot the scatter of the shap values\n",
    "# against the histogram of the distribution\n",
    "# in the same figure\n",
    "# using matplotlib instead of shap\n",
    "ax = plt.figure(figsize=(5, 5), dpi=300).add_subplot(111)\n",
    "ax2 = ax.twinx()\n",
    "source_ids = overall_shap_values.index.str.split(\"_\").str[0].astype(np.int64)\n",
    "source_ids_random = random_shap_sample.index.str.split(\"_\").str[-1].astype(np.int64)\n",
    "# print(source_ids)\n",
    "# for each source_id get the corresponding index in X\n",
    "data_idx = [df_big[df_big.source_id == source_id].index[0] for source_id in source_ids]\n",
    "random_idx = [df_big[df_big.source_id == source_id].index[0] for source_id in source_ids_random]\n",
    "vals = random_shap_sample[feature].values\n",
    "random_idx_ssc = []\n",
    "random_idx_nss = []\n",
    "random_val_ssc = []\n",
    "random_val_nss = []\n",
    "\n",
    "# Split into NSS and SSC\n",
    "for row, idx in enumerate(random_idx):\n",
    "    if not df_big.iloc[idx].label in [\n",
    "        \"substellar_companion_candidates\",\n",
    "        \"better_substellar_companion_candidates\",\n",
    "        \"very_low_mass_stellar_companion\",\n",
    "        \"exoplanet\",\n",
    "        \"brown_dwarf_companion\",\n",
    "        \"binary_star\",\n",
    "    ]:\n",
    "        random_val_nss.append(vals[row])\n",
    "        random_idx_nss.append(idx)\n",
    "    else:\n",
    "        random_val_ssc.append(vals[row])\n",
    "        random_idx_ssc.append(idx)\n",
    "\n",
    "\n",
    "# print(data_idx)\n",
    "# Get the X values for this feature allowing duplicate rows\n",
    "X_candidates = X_big.iloc[data_idx]\n",
    "X_nss = X_big.iloc[random_idx_nss]\n",
    "X_ssc = X_big.iloc[random_idx_ssc]\n",
    "# print(X_candidates)\n",
    "# Plot the shap values as scatter\n",
    "\n",
    "ax2.scatter(\n",
    "    X_ssc[feature].values, np.abs(random_val_ssc), alpha=1.0, marker=\"d\", color=\"#1b9e77\", s=8\n",
    ")\n",
    "\n",
    "ax2.scatter(\n",
    "    X_nss[feature].values, np.abs(random_val_nss), alpha=1.0, marker=\"s\", color=\"#d95f02\", s=8\n",
    ")\n",
    "\n",
    "ax2.scatter(\n",
    "    X_candidates[feature].values,\n",
    "    np.abs(overall_shap_values[feature].values),\n",
    "    alpha=1.0,\n",
    "    color=\"#7570b3\",\n",
    "    s=8,\n",
    ")\n",
    "\n",
    "# Using transparent alpha to make the histogram in the background\n",
    "# Create log bins if feature is mass_function_msun or radial_velocity_error\n",
    "if feature == \"mass_function_msun\" or feature == \"radial_velocity_error\":\n",
    "    bins = np.logspace(\n",
    "        np.log10(X_big[feature].min()),\n",
    "        np.log10(X_big[feature].max()),\n",
    "        100,\n",
    "    )\n",
    "else:\n",
    "    bins = 100\n",
    "\n",
    "ax.hist(X_big[feature].values, bins=bins, alpha=0.25)\n",
    "\n",
    "# if feature is mass_function_msun or radial_velocity_error we make the x axis logarithmic\n",
    "if feature == \"mass_function_msun\" or feature == \"radial_velocity_error\":\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax2.set_xscale(\"log\")\n",
    "ax2.set_xlim(10e-8, 1)\n",
    "# ax.set_yscale(\"log\")\n",
    "ax2.set_yscale(\"log\")\n",
    "ax.set_xlabel(feature)\n",
    "ax.set_ylabel(\"Histogram\")\n",
    "ax2.set_ylabel(\"Absolute SHAP values\")\n",
    "ax2.legend([\"Preselected Sources\", \"Non-single Sources\", \"Our Candidates\"], loc=\"lower left\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"paper/\" + feature + \".pdf\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and Print Average Scores\n",
    "This cell calculates average scores for different categories and prints them in a format suitable for LaTeX tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv(\"results/all_scores.csv\")\n",
    "scores = scores.set_index(\"Unnamed: 0\")\n",
    "# Drop row with f1\n",
    "scores = scores.iloc[1:]\n",
    "all_columns = scores.columns\n",
    "# Average colums where better_ssc=0 and better_ssc=1\n",
    "better_ssc_0 = []\n",
    "better_ssc_1 = []\n",
    "nss = []\n",
    "ssc = []\n",
    "xgb = []\n",
    "rf = []\n",
    "for col in all_columns:\n",
    "    if \"better_ssc=0\" in col:\n",
    "        better_ssc_0.append(col)\n",
    "    if \"better_ssc=1\" in col:\n",
    "        better_ssc_1.append(col)\n",
    "    if \"nss\" in col:\n",
    "        nss.append(col)\n",
    "    if \"ssc\" in col:\n",
    "        ssc.append(col)\n",
    "    if \"xgb\" in col:\n",
    "        xgb.append(col)\n",
    "    if \"rf\" in col:\n",
    "        rf.append(col)\n",
    "\n",
    "# Average the columns\n",
    "scores[\"better_ssc=0\"] = scores[better_ssc_0].mean(axis=1)\n",
    "scores[\"better_ssc=1\"] = scores[better_ssc_1].mean(axis=1)\n",
    "scores[\"nss\"] = scores[nss].mean(axis=1)\n",
    "scores[\"ssc\"] = scores[ssc].mean(axis=1)\n",
    "scores[\"xgb\"] = scores[xgb].mean(axis=1)\n",
    "scores[\"rf\"] = scores[rf].mean(axis=1)\n",
    "scores[\"all\"] = scores.mean(axis=1)\n",
    "scores = scores[[\"better_ssc=0\", \"better_ssc=1\", \"nss\", \"ssc\", \"xgb\", \"rf\", \"all\"]]\n",
    "scores\n",
    "\n",
    "# Print entries with & inbetween for latex\n",
    "for row in scores.iterrows():\n",
    "    print(\n",
    "        row[0],\n",
    "        \"&\",\n",
    "        \" & \".join([str(round(x, 2)) for x in row[1].values]),\n",
    "        \"\\\\\\\\\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Unique Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(candidates.source_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Dataset Labels\n",
    "This cell prints the label distribution in a specific dataset and calculates the number of non-single sources (NSS) and single sources (SSC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datasets[\"results\\\\top_rf_nss_label_for_better_ssc=0.csv\"][3].label.value_counts())\n",
    "N_nss = datasets[\"results\\\\top_rf_nss_label_for_better_ssc=0.csv\"][3].label.isna().sum()\n",
    "print(\"N_nss:\", N_nss)\n",
    "print(\"Total Length:\", len(datasets[\"results\\\\top_rf_nss_label_for_better_ssc=0.csv\"][3]))\n",
    "print(\"N_ssc:\", len(datasets[\"results\\\\top_rf_nss_label_for_better_ssc=0.csv\"][3]) - N_nss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Features\n",
    "This cell counts the number of features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Radial Velocity Error Histograms\n",
    "This cell plots histograms of radial velocity error for different categories on a logarithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of radial velocity error of candidates, ssc, and nss on logscale\n",
    "plt.figure(figsize=(8, 3), dpi=300)\n",
    "# Enlarge font size for this plot\n",
    "plt.rcParams.update({\"font.size\": 12})\n",
    "nss_rv = df_big[df_big.label.isna()].radial_velocity_error\n",
    "ssc_rv = df_big[~df_big.label.isna()].radial_velocity_error\n",
    "cand_rv = df_big[df_big.source_id.isin(candidates.source_id)].radial_velocity_error\n",
    "confirmed_rv = df_big[\n",
    "    df_big.label.isin([\"exoplanet\", \"brown_dwarf_companion\"])\n",
    "].radial_velocity_error\n",
    "logscale_bins = np.logspace(np.log10(0.1), np.log10(100), 100)\n",
    "plt.hist(\n",
    "    nss_rv, bins=logscale_bins, alpha=1.0, label=\"Non-single Source\", color=\"#1b9e77\", log=True\n",
    ")\n",
    "plt.hist(\n",
    "    ssc_rv, bins=logscale_bins, alpha=1.0, label=\"Preselected Sources\", color=\"#d95f02\", log=True\n",
    ")\n",
    "plt.hist(cand_rv, bins=logscale_bins, alpha=1.0, label=\"Our Candidates\", color=\"#7570b3\", log=True)\n",
    "plt.hist(confirmed_rv, bins=logscale_bins, alpha=1.0, label=\"Confirmed\", color=\"black\", log=True)\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Radial Velocity Error\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"paper/rv_error_hist.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Data Loading\n",
    "This cell sets the logging level to DEBUG to examine details of the data loading process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_ad.set_log_level(\"DEBUG\")  # Look at details of data loading\n",
    "_ = load_data(\n",
    "    dataset_version=\"0.0.6\",\n",
    "    drop_NSS=False,\n",
    "    make_binary=True,\n",
    "    clean=True,\n",
    "    drop_nan_columns=False,\n",
    "    drop_nan_rows=False,\n",
    "    label_for_high_confidence_substellar=method.split(\".csv\")[0][-1],\n",
    "    path=\"data/0.0.6/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Specific Source IDs\n",
    "This cell finds and prints scores for specific source IDs, including the worst scoring detected brown dwarf (BD) and a source just under 0.5 relative occurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find scores for 3751763647996317056 and 5563001178343925376 (worst scoring detected BD) and 2280560705703031552 (just under 0.5 relative occurence)\n",
    "source_id = 3751763647996317056\n",
    "source_id_found = 5563001178343925376\n",
    "source_id_not_found = 2280560705703031552\n",
    "score_files = glob(\"results/worst_truepositive_*\")\n",
    "top_score_files = glob(\"results/top*\")\n",
    "print(score_files)\n",
    "print(top_score_files)\n",
    "# Load the scores\n",
    "scores = []\n",
    "scores_found = []\n",
    "scores_not_found = []\n",
    "for score_file, top_file in zip(score_files, top_score_files):\n",
    "    # load csv\n",
    "    model_scores = pd.read_csv(score_file)\n",
    "    # Get the source_id\n",
    "    score = model_scores[model_scores.source_id == source_id]\n",
    "    score_found = model_scores[model_scores.source_id == source_id_found]\n",
    "    top_scores = pd.read_csv(top_file)\n",
    "    scores.append(score.predictions.values[0])\n",
    "    scores_found.append(score_found.predictions.values[0])\n",
    "    try:\n",
    "        score_not_found = top_scores[top_scores.source_id == source_id_not_found]\n",
    "        scores_not_found.append(score_not_found.predictions.values[0])\n",
    "    except:\n",
    "        scores_not_found.append(0)\n",
    "print(scores)\n",
    "print(scores_found)\n",
    "print(scores_not_found)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaia_ad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
